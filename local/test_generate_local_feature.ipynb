{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e515ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# assert len(sys.argv) == 3, f'Usage: python {sys.argv[0]} <features_path> <original_pdb_path>'\n",
    "sys.argv[1] = '.var/features.pkl'\n",
    "sys.argv[2] = '../af2-standard_T1104_3'\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "from math import sqrt\n",
    "from torch.utils import data\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from time import gmtime, strftime\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "script_dir = './'\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, channels,relu=0.1, dp=0.1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.num_layers = len(channels) - 1\n",
    "        self.ks = 5\n",
    "        self.dv = 1\n",
    "        self.resblocks3d = nn.ModuleList()\n",
    "        self.relu = nn.LeakyReLU(relu)\n",
    "        for i in range(self.num_layers):\n",
    "            #print('i',i,channels[i], channels[i+1])\n",
    "            layer_conv3d = torch.nn.Conv3d(channels[i], channels[i+1], kernel_size=self.ks, stride=1,\n",
    "                                           padding=int(self.dv*(self.ks-1)/2), dilation=self.dv)\n",
    "            nn.init.xavier_uniform_(layer_conv3d.weight, gain=sqrt(2.0))\n",
    "            # append layers\n",
    "            self.resblocks3d.append(layer_conv3d)\n",
    "            self.resblocks3d.append(nn.BatchNorm3d(channels[i+1], affine=True))\n",
    "            self.resblocks3d.append(nn.LeakyReLU(relu))\n",
    "            self.resblocks3d.append(nn.Dropout(p=dp))\n",
    "        self.out = torch.nn.Conv3d(channels[i+1],1, kernel_size=self.ks, stride=1,\n",
    "                                           padding=int(self.dv*(self.ks-1)/2), dilation=self.dv)\n",
    "        nn.init.xavier_uniform_(self.out.weight, gain=sqrt(2.0))\n",
    "        self.norm = nn.BatchNorm3d(1, affine=True)\n",
    "    def forward(self, x):\n",
    "        #print(self.num_layers, len(self.resblocks3d),)\n",
    "        for layer_i in range(0,self.num_layers,1):\n",
    "            i = layer_i*4\n",
    "            # block 1\n",
    "            residual = x # make pointer to data stored at x\n",
    "            x = self.resblocks3d[i](x) # x now points to different data, residual still points to old x\n",
    "            x = self.resblocks3d[i+1](x)\n",
    "            x = self.resblocks3d[i+2](x)\n",
    "            x = self.resblocks3d[i+3](x)\n",
    "            x = x + residual # residual skip connection\n",
    "        x = self.norm(self.out(x))\n",
    "        return x\n",
    "\n",
    "# create model\n",
    "relu=0.1\n",
    "dp=0.1\n",
    "model_channels = [10,10,10,10,10,   10,10,10,10,10,   10,10,10,10,10,   10,10,10,10,10,   10,10,10,10,10,   10,10,10,10,10,   10,10] # 32 conv blocks, 1 output block\n",
    "device = torch.device('cuda:0')\n",
    "model = ResNet(model_channels,relu, dp).eval()\n",
    "model.to(device)\n",
    "# ts13\n",
    "model_f = f'{script_dir}/util/local_trained_model.gcn'\n",
    "if not os.path.exists(model_f):\n",
    "    raise FileNotFoundError\n",
    "model.load_state_dict(torch.load(model_f,map_location='cuda:0'))\n",
    "# print('create model',flush=True)\n",
    "# CASP15 Group\n",
    "AUTHOR = {'QUIC':'4898-0423-8007','PICNIC':'2613-7296-5647'}\n",
    "AUTHOR_QUIC = '4898-0423-8007'\n",
    "METHOD = '3D Convolutional Neural Network'\n",
    "\n",
    "# allTargets = ['T1129s2', 'T1133', 'T1134s1', 'T1134s2', 'T1137s1', 'T1137s2', 'T1137s3', 'T1137s4', 'T1137s5', 'T1137s6', 'T1137s7', 'T1137s8', 'T1137s9', 'T1145', 'T1151s2', 'T1152', 'T1159', 'T1170', 'T1176', 'T1185s1', 'T1185s2', 'T1185s4', 'T1187', 'T1188']\n",
    "\n",
    "df_pred_pkl = sys.argv[1]\n",
    "\n",
    "if '/' in sys.argv[2]:\n",
    "    save_dir = sys.argv[2].replace(sys.argv[2].split('/')[-1],'')\n",
    "else:\n",
    "    # file in cwd\n",
    "    save_dir = './'\n",
    "\n",
    "\n",
    "# for target in allTargets:\n",
    "# print('\\nTarget',target,flush=True)\n",
    "# df_pred_pkls = glob.glob(f'./data-casp15/feature_TS_model/af2-*_{target}_*.pkl')\n",
    "# df_pred_pkls = [i for i in df_pred_pkls if not '_out.pkl' in i]\n",
    "\n",
    "# if len(df_pred_pkls) == 0:\n",
    "#     print(f'no features of {target} at ./data-casp15/feature_TS_model/',flush=True)\n",
    "#     continue\n",
    "\n",
    "# save to \n",
    "# save_dir = f'data-casp15/refined_model/{target}/'\n",
    "# if not os.path.exists(save_dir):\n",
    "#     os.system(f'mkdir {save_dir}')\n",
    "# data set\n",
    "resolution = 0.1\n",
    "# for df_pred_pkl in df_pred_pkls:\n",
    "# print(f'Prediction for {df_pred_pkl}',flush=True)\n",
    "# 'model_domain','idx', 'residue', 'resSeq', 'atom', 'features','atom_coord'\n",
    "df_pred = pd.read_pickle(df_pred_pkl)\n",
    "\n",
    "if '.pdb' == sys.argv[2].split(\"/\")[-1][:-4]:\n",
    "    PDB_f = f'{save_dir}{sys.argv[2].split(\"/\")[-1].replace(\".pdb\",\"_PICNIC2-LOCAL_out.pdb\")}'\n",
    "else:\n",
    "    PDB_f = f'{save_dir}{sys.argv[2].split(\"/\")[-1]+\"_PICNIC2-LOCAL_out.pdb\"}'\n",
    "\n",
    "PDB_fh = open(PDB_f,'w')\n",
    "PDB_TEXT = ''\n",
    "clip_b = 0.025\n",
    "\n",
    "for i,row in df_pred.iterrows():\n",
    "    x = row.features\n",
    "    x = x.to_dense()\n",
    "    x = Variable(x).to(device, dtype=torch.float)\n",
    "    x = torch.unsqueeze(x, 0)\n",
    "    out = model(x)\n",
    "    out = torch.squeeze(out, 0)\n",
    "    out = torch.squeeze(out, 1).cpu().detach().numpy()\n",
    "    new_cen = 40\n",
    "#             new_cen = math.floor(1.0 / resolution)  # 16 angstrom look in each direction\n",
    "    out = out[:,40-new_cen:41+new_cen,40-new_cen:41+new_cen,40-new_cen:41+new_cen]\n",
    "    out_max = np.amax(out)\n",
    "    max_clip_angstroms = 999999\n",
    "    max_clip_cube = max_clip_angstroms / resolution\n",
    "    _, out_x,out_y,out_z = np.where(out == out_max) \n",
    "\n",
    "    if out_max > 16: # 16 sigmoid k best so far\n",
    "        # No refine if too confident\n",
    "        out_x[0],out_y[0],out_z[0] = new_cen,new_cen,new_cen\n",
    "\n",
    "    shift_cube = np.array([out_x[0],out_y[0],out_z[0]])-new_cen\n",
    "    # b':0.025\n",
    "    out_refine = np.clip((shift_cube)*resolution,-clip_b,clip_b)\n",
    "    #print(i,out_x,out_y,out_z)\n",
    "#             out_refine = (np.array([out_x[0],out_y[0],out_z[0]])-40)*0.1 # resolution\n",
    "\n",
    "#     df_result.append([row.atom,row.residue,row.resSeq,row.atom_coord,out_refine])\n",
    "    #print(np.clip(out_refine,-0.2,0.2))\n",
    "#             if out_refine[0] == 0 and out_refine[1] == 0 and out_refine[2] == 0:\n",
    "#                 print(f'saved_f {target} {out_refine}',flush=True)\n",
    "    out_coord  = row.atom_coord + out_refine\n",
    "    #print(out,out_max,torch.max(out))\n",
    "    #             ATOM   4689  CE3 TRP   302      -4.324   4.177  -7.944  1.00 93.80              \\n\n",
    "    atom_num = ' '*(5-len(str(i+1))) + str(i+1)                   #7-11\n",
    "    atom_name = row.atom +' '*(4-len(row.atom))                   #13-16\n",
    "    residue_name = row.residue                                    #18-20\n",
    "    residue_num = ' '*(4-len(str(row.resSeq))) + str(row.resSeq)  # 23-26\n",
    "\n",
    "    x_coord = ' '*(8-len(f'{round(out_coord[0],3):.3f}')) + f'{round(out_coord[0],3):.3f}' # 31-38\n",
    "    y_coord = ' '*(8-len(f'{round(out_coord[1],3):.3f}')) + f'{round(out_coord[1],3):.3f}' # 39-46\n",
    "    z_coord = ' '*(8-len(f'{round(out_coord[2],3):.3f}')) + f'{round(out_coord[2],3):.3f}' # 47-54\n",
    "    ATOM_line = 'ATOM  '+atom_num+' '+atom_name+' '+residue_name+'  '+residue_num+' '*4+x_coord+y_coord+z_coord+'  1.00  90.0           '+(atom_name if atom_name != 'CA' else 'C')\n",
    "    PDB_TEXT += ATOM_line + '\\n'\n",
    "\n",
    "    #print(ATOM_line)\n",
    "# df_result = pd.DataFrame(df_result,columns=['atom','residue','resSeq','atom_coord','out_refine'])\n",
    "# df_result.to_pickle(df_pred_pkl.replace('.pkl','_PICNIC2_out.pkl'))\n",
    "        \n",
    "    # Convert .pkl file to .pdb file\n",
    "    # Clip tags\n",
    "#     for tag in ['a','b','c','d','e']:\n",
    "#     os.system(f'python prediction_PICNIC2_clip_from_savedf.py {target} b 0')\n",
    "    #os.system(f'python prediction_PICNIC2_sigmoid_from_savedf.py {target} k 0')\n",
    "#     os.system(f'python prediction_PICNIC2_from_savedf.py {target}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2dffc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../af2-standard_T1104_3_PICNIC2-LOCAL_out.pdb\n"
     ]
    }
   ],
   "source": [
    "with open(sys.argv[2],'r') as input_pdb:\n",
    "    input_lines = input_pdb.readlines()\n",
    "# print(sys.argv[2])\n",
    "out_lines = PDB_TEXT.split('\\n')\n",
    "if len(out_lines[-1]) == 0:\n",
    "    del out_lines[-1]\n",
    "# atom name, residue number, x, y, z coords\n",
    "out_change = [[line[12:16],line[22:27],line[30:38],line[38:46],line[46:54]] for line in out_lines]\n",
    "out_atom = out_change.pop(0)\n",
    "\n",
    "out_pdb_lines = []\n",
    "# print(len(input_lines))\n",
    "for line in input_lines:\n",
    "#     print(len(out_change))\n",
    "#     print('input pdb  ',line)\n",
    "#     new_line_test = list(line)\n",
    "#     new_line_test[12:16] = out_atom[0]\n",
    "#     new_line_test[22:27] = out_atom[1]\n",
    "#     new_line_test = ''.join(new_line_test)\n",
    "#     print('looking for',new_line_test)\n",
    "    if line[12:16].replace(' ','') == out_atom[0].replace(' ','') and line[22:27].replace(' ','') == out_atom[1].replace(' ',''):\n",
    "        # Update coords if atoms and residues match\n",
    "        line_list = list(line)\n",
    "        line_list[30:38],line_list[38:46],line_list[46:54] = out_atom[2],out_atom[3],out_atom[4]\n",
    "        line = ''.join(line_list)\n",
    "        if len(out_change) != 0:\n",
    "            out_atom = out_change.pop(0)\n",
    "    out_pdb_lines.append(line)\n",
    "# print(out_change)\n",
    "assert len(out_change) == 0, 'PDB update failed'\n",
    "NEW_PDB_TEXT = ''.join(out_pdb_lines)\n",
    "PDB_fh.write(NEW_PDB_TEXT)\n",
    "PDB_fh.close()\n",
    "print(PDB_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c2c914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pred_env",
   "language": "python",
   "name": "pred_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
